{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5684a9ad",
   "metadata": {},
   "source": [
    "# Stage 2 Evaluation Harness (Preview + Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcd0386",
   "metadata": {},
   "source": [
    "This notebook wires the Stage 2 coverage preview directly into the full Stage 2 evaluation harness. It is designed for sanity checking, early warning, and final field-level precision/recall evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standard library imports\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from typing import Dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217cf14f",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb86a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GOLD_PATH = \"training_data/stage2_gold_val.json\"\n",
    "PRED_PATH = \"training_data/stage2_pred_val.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0b046d",
   "metadata": {},
   "source": [
    "## Load and Index Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b34e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_index(gold_path: str, pred_path: str):\n",
    "    with open(gold_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        gold = json.load(f)\n",
    "\n",
    "    with open(pred_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        pred = json.load(f)\n",
    "\n",
    "    gold_by_id = {r[\"reference_id\"]: r for r in gold}\n",
    "    pred_by_id = {r[\"reference_id\"]: r for r in pred}\n",
    "\n",
    "    if gold_by_id.keys() != pred_by_id.keys():\n",
    "        raise ValueError(\"Gold / prediction reference_id mismatch\")\n",
    "\n",
    "    return gold_by_id, pred_by_id\n",
    "\n",
    "\n",
    "gold_by_id, pred_by_id = load_and_index(GOLD_PATH, PRED_PATH)\n",
    "\n",
    "print(f\"Loaded {len(gold_by_id)} records\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8329b2f",
   "metadata": {},
   "source": [
    "## Stage 2 Coverage Preview (Pre-flight Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94b19c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def coverage_preview(gold_by_id: Dict, pred_by_id: Dict):\n",
    "    field_stats = defaultdict(lambda: {\"gold_filled\": 0, \"pred_filled\": 0})\n",
    "    warnings = []\n",
    "\n",
    "    for ref_id in gold_by_id:\n",
    "        gold_fields = gold_by_id[ref_id][\"stage2_gold\"][\"fields\"]\n",
    "        pred_fields = pred_by_id[ref_id][\"stage2_output\"][\"fields\"]\n",
    "\n",
    "        for field, gold_obj in gold_fields.items():\n",
    "            pred_obj = pred_fields.get(field, {})\n",
    "\n",
    "            if gold_obj.get(\"value\") not in (None, \"\", []):\n",
    "                field_stats[field][\"gold_filled\"] += 1\n",
    "\n",
    "            if pred_obj.get(\"value\") not in (None, \"\", []):\n",
    "                field_stats[field][\"pred_filled\"] += 1\n",
    "\n",
    "    for field, stats in field_stats.items():\n",
    "        if stats[\"gold_filled\"] > 0:\n",
    "            coverage = stats[\"pred_filled\"] / stats[\"gold_filled\"]\n",
    "            if coverage < 0.5:\n",
    "                warnings.append(\n",
    "                    f\"Low coverage for field '{field}': {coverage:.2f}\"\n",
    "                )\n",
    "\n",
    "    return field_stats, warnings\n",
    "\n",
    "\n",
    "field_stats, warnings = coverage_preview(gold_by_id, pred_by_id)\n",
    "\n",
    "print(\"=== Coverage Preview ===\")\n",
    "for field, stats in field_stats.items():\n",
    "    print(\n",
    "        f\"{field:<15} | Gold filled: {stats['gold_filled']:<3} \"\n",
    "        f\"| Pred filled: {stats['pred_filled']:<3}\"\n",
    "    )\n",
    "\n",
    "if warnings:\n",
    "    print(\"\\nWarnings:\")\n",
    "    for w in warnings:\n",
    "        print(\"⚠️\", w)\n",
    "else:\n",
    "    print(\"\\nNo coverage warnings.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9870f52d",
   "metadata": {},
   "source": [
    "## Full Stage 2 Field-Level Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672880ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_stage2(gold_by_id: Dict, pred_by_id: Dict):\n",
    "    results = defaultdict(lambda: {\"tp\": 0, \"fp\": 0, \"fn\": 0})\n",
    "\n",
    "    for ref_id in gold_by_id:\n",
    "        gold_fields = gold_by_id[ref_id][\"stage2_gold\"][\"fields\"]\n",
    "        pred_fields = pred_by_id[ref_id][\"stage2_output\"][\"fields\"]\n",
    "\n",
    "        for field, gold_obj in gold_fields.items():\n",
    "            gold_val = gold_obj.get(\"value\")\n",
    "            pred_val = pred_fields.get(field, {}).get(\"value\")\n",
    "\n",
    "            if gold_val not in (None, \"\", []):\n",
    "                if pred_val == gold_val:\n",
    "                    results[field][\"tp\"] += 1\n",
    "                else:\n",
    "                    results[field][\"fn\"] += 1\n",
    "\n",
    "            if pred_val not in (None, \"\", []) and pred_val != gold_val:\n",
    "                results[field][\"fp\"] += 1\n",
    "\n",
    "    metrics = {}\n",
    "    for field, r in results.items():\n",
    "        tp, fp, fn = r[\"tp\"], r[\"fp\"], r[\"fn\"]\n",
    "\n",
    "        precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "        f1 = (\n",
    "            2 * precision * recall / (precision + recall)\n",
    "            if (precision + recall)\n",
    "            else 0.0\n",
    "        )\n",
    "\n",
    "        metrics[field] = {\n",
    "            \"precision\": round(precision, 3),\n",
    "            \"recall\": round(recall, 3),\n",
    "            \"f1\": round(f1, 3),\n",
    "            \"tp\": tp,\n",
    "            \"fp\": fp,\n",
    "            \"fn\": fn\n",
    "        }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "metrics = evaluate_stage2(gold_by_id, pred_by_id)\n",
    "\n",
    "print(\"=== Stage 2 Evaluation Metrics ===\")\n",
    "for field, m in metrics.items():\n",
    "    print(field, m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e977e050",
   "metadata": {},
   "source": [
    "## Combined Evaluation Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa1d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "report = {\n",
    "    \"coverage_preview\": {\n",
    "        \"field_stats\": field_stats,\n",
    "        \"warnings\": warnings\n",
    "    },\n",
    "    \"metrics\": metrics\n",
    "}\n",
    "\n",
    "print(json.dumps(report, indent=2))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}